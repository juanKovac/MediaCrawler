# 小红书爬虫功能增强计划

## 项目概述
本文档记录了对小红书爬虫项目的功能增强计划，主要解决以下三个核心问题：
1. 增量爬取剩余笔记
2. 自动获取最新笔记
3. 记录数据变化

## 当前项目状态分析

### 已有功能
- ✅ 基础爬取功能（关键词搜索、创作者笔记）
- ✅ 多种存储格式支持（CSV、JSON、SQLite、MySQL）
- ✅ 评论爬取功能
- ✅ Web界面管理
- ✅ 代理IP支持
- ✅ 多平台支持（小红书、抖音、微博等）

### 缺失功能
- ❌ 增量爬取机制
- ❌ 完整爬取模式（突破200条限制）
- ❌ 自动更新检测
- ❌ 数据变化追踪
- ❌ 爬取状态保存（断点续爬）

## 功能增强方案

### 1. 增量爬取和完整爬取功能

#### 1.1 配置文件修改 (`config/base_config.py`)
```python
# 新增配置项
ENABLE_FULL_CRAWL = False  # 是否启用完整爬取模式
ENABLE_RESUME_CRAWL = False  # 是否启用断点续爬
CRAWL_BATCH_SIZE = 50  # 每批次爬取数量
CRAWL_INTERVAL = 2  # 爬取间隔（秒）
```

#### 1.2 客户端功能增强 (`media_platform/xhs/client.py`)
需要修改 `get_all_notes_by_creator` 方法，新增以下功能：
- 状态保存机制
- 断点续爬逻辑
- 完整爬取模式

```python
def save_crawl_state(self, creator_id: str, last_cursor: str, crawled_count: int):
    """保存爬取状态"""
    
def load_crawl_state(self, creator_id: str):
    """加载爬取状态"""
    
def clear_crawl_state(self, creator_id: str):
    """清除爬取状态"""
```

### 2. 自动更新机制

#### 2.1 核心功能 (`media_platform/xhs/core.py`)
新增自动更新相关方法：

```python
async def get_creators_updates(self, creator_ids: List[str]):
    """获取多个创作者的更新"""
    
async def get_latest_notes_since(self, creator_id: str, since_time: datetime):
    """获取指定时间后的最新笔记"""
    
def get_last_crawl_time(self, creator_id: str) -> datetime:
    """获取上次爬取时间"""
    
def update_last_crawl_time(self, creator_id: str, crawl_time: datetime):
    """更新上次爬取时间"""
```

#### 2.2 配置选项
```python
ENABLE_AUTO_UPDATE = False  # 是否启用自动更新
AUTO_UPDATE_INTERVAL = 3600  # 自动更新间隔（秒）
AUTO_UPDATE_CREATORS = []  # 需要自动更新的创作者列表
```

### 3. 数据变化追踪系统

#### 3.1 存储实现增强 (`store/xhs/xhs_store_impl.py`)
修改 `XhsCsvStoreImplement` 类，新增变化追踪功能：

```python
def track_content_changes(self, note_data: Dict):
    """追踪内容变化"""
    
def detect_changes(self, old_data: Dict, new_data: Dict) -> Dict:
    """检测数据变化"""
    
def save_change_log(self, note_id: str, changes: Dict):
    """保存变化日志"""
```

#### 3.2 配置选项
```python
ENABLE_CHANGE_TRACKING = False  # 是否启用变化追踪
TRACK_FIELDS = ['liked_count', 'collected_count', 'comment_count', 'title', 'desc']  # 追踪字段
CHANGE_LOG_FORMAT = 'csv'  # 变化日志格式
```

## 文件结构规划