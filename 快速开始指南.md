# 🚀 MediaCrawler 快速开始指南

## ✅ 部署完成确认

恭喜！MediaCrawler 项目已经成功部署到您的本地环境：

- ✅ 项目代码已下载完成
- ✅ uv 包管理工具已安装 (v0.8.9)
- ✅ Node.js 环境已就绪 (v22.15.0) 
- ✅ Python 依赖包已安装完成
- ✅ Playwright 浏览器驱动已安装
- ✅ 程序测试运行正常

## 🎯 立即开始使用

### 第一步：选择平台和关键词

```bash
# 小红书搜索（推荐新手）
uv run main.py --platform xhs --lt qrcode --type search --keywords "Python学习" --save_data_option json

# 抖音搜索
uv run main.py --platform dy --lt qrcode --type search --keywords "编程教程" --save_data_option json

# B站搜索
uv run main.py --platform bili --lt qrcode --type search --keywords "前端开发" --save_data_option json
```

### 第二步：扫码登录

1. 运行命令后，程序会自动打开浏览器
2. 使用对应平台的手机APP扫描二维码
3. 等待登录成功提示
4. 程序开始自动爬取数据

### 第三步：查看结果

爬取完成后，数据会保存在 `data/` 目录下：

```
data/
├── xhs/
│   ├── json/
│   │   ├── notes/          # 帖子数据
│   │   └── comments/       # 评论数据
│   └── images/             # 图片文件（如果开启）
└── ...
```

## 📋 常用命令速查

### 平台代码
- `xhs` - 小红书
- `dy` - 抖音  
- `ks` - 快手
- `bili` - B站
- `wb` - 微博
- `tieba` - 百度贴吧
- `zhihu` - 知乎

### 爬取类型
- `search` - 关键词搜索
- `detail` - 指定帖子详情
- `creator` - 创作者主页

### 数据保存格式
- `json` - JSON文件（推荐）
- `csv` - CSV文件
- `sqlite` - SQLite数据库
- `db` - MySQL数据库

## ⚡ 实用技巧

### 1. 批量关键词搜索

修改 `config/base_config.py` 文件：

```python
KEYWORDS = "Python编程,前端开发,数据分析,机器学习"
```

### 2. 控制爬取数量

```python
# 在 config/base_config.py 中设置
CRAWLER_MAX_NOTES_COUNT = 50  # 最大帖子数
CRAWLER_MAX_COMMENTS_COUNT_SINGLENOTES = 20  # 单帖最大评论数
```

### 3. 开启评论爬取

```bash
uv run main.py --platform xhs --lt qrcode --type search --get_comment true
```

### 4. 保存到数据库

```bash
# 使用 SQLite（推荐）
uv run main.py --platform xhs --lt qrcode --type search --save_data_option sqlite
```

## 🔧 配置文件说明

主要配置文件位于 `config/` 目录：

- `base_config.py` - 基础配置
- `xhs_config.py` - 小红书专用配置
- `dy_config.py` - 抖音专用配置
- `bili_config.py` - B站专用配置
- 等等...

### 重要配置项

```python
# config/base_config.py

# 是否显示浏览器窗口（建议设为 False 方便调试）
HEADLESS = False

# 是否保存登录状态（建议开启）
SAVE_LOGIN_STATE = True

# 是否爬取评论
ENABLE_GET_COMMENTS = True

# 是否下载图片/视频
ENABLE_GET_MEIDAS = False
```

## ⚠️ 重要提醒

### 法律合规
- 🚨 **仅供学习研究使用，禁止商业用途**
- 🚨 **遵守各平台使用条款**
- 🚨 **不要进行大规模爬取**
- 🚨 **合理控制爬取频率**

### 使用建议
- 💡 首次使用建议先测试小红书，相对稳定
- 💡 爬取数量不要设置过大（建议50以内）
- 💡 如遇验证码，手动处理后继续
- 💡 定期清理 `data/` 目录避免占用过多空间

### 常见问题解决

**Q: 登录失败怎么办？**
A: 设置 `HEADLESS = False`，手动处理验证码

**Q: 程序卡住不动？**
A: 可能遇到反爬机制，等待几分钟或重启程序

**Q: 数据为空？**
A: 检查关键词设置和网络连接

**Q: 浏览器启动失败？**
A: 重新安装驱动：`uv run playwright install`

## 📊 数据分析示例

爬取完成后，您可以使用 Python 分析数据：

```python
import json
import pandas as pd

# 读取帖子数据
with open('data/xhs/json/notes/notes_20231213.json', 'r', encoding='utf-8') as f:
    notes_data = json.load(f)

# 转换为 DataFrame
df = pd.DataFrame(notes_data)

# 分析点赞数分布
print(df['liked_count'].describe())

# 查看热门帖子
hot_notes = df.nlargest(10, 'liked_count')[['title', 'liked_count', 'collected_count']]
print(hot_notes)
```

## 🎉 开始您的数据采集之旅

现在您已经掌握了 MediaCrawler 的基本使用方法，可以开始探索各个平台的数据了！

记住：
- 🎯 **明确目标** - 确定要采集什么数据
- 🔍 **精准关键词** - 使用准确的搜索关键词
- 📊 **合理分析** - 对采集的数据进行有意义的分析
- 🤝 **合规使用** - 始终遵守法律法规和平台规则

祝您使用愉快！🚀